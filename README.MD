# Gleitzsch

*realâ€‘time glitchâ€‘art camera for iOS*

Gleitzsch captures the live camera feed, runs it through a **Metalâ€‘accelerated FFT glitch pipeline** and shows the result with <8â€¯ms total latency on modern iPhones. The architecture is deliberately modular, so you can hotâ€‘swap filters or add UI sliders without touching the core loop.

---

## ðŸ”§ Highâ€‘level pipeline

```text
AVFoundation camera (NV12)
â†“
CIImage  â†’  CGImage                 // oriented to `.right`
â†“        resize to 512Ã—512 (CPU)
FrameProcessor
â†“
MetalFFTFilter (GPU)
   â”œâ”€â”€ transpose512        // rowâ€‘major â†’ colâ€‘major
   â”œâ”€â”€ fft1D_512           // 1â€‘D FFT per visual *column*
   â”œâ”€â”€ killBands_1D_512    // zero low / high freq bins
   â”œâ”€â”€ ifft1D_512          // inverse FFT
   â””â”€â”€ transpose512        // colâ€‘major â†’ rowâ€‘major
â†“
CGImage  â†’  SwiftUI
```

All heavy lifting (FFT + frequency surgery) happens on the GPU; the CPU only copies the RGB float array into a persistent Metal buffer and back.

---

## âš™ï¸  Metal filter details

| Step               | Kernel             | Notes                                                                                                                                                |
| ------------------ | ------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Transpose**      | `transpose512`     | 16Ã—16 tiled transpose to turn columns into contiguous rows.                                                                                          |
| **FFT**            | `fft1D_512`        | Cooleyâ€‘Tukey radixâ€‘2, unrolled for **NÂ =Â 512**. Runs once per visual column (i.e. per original row).                                                 |
| **KillÂ Bands**     | `killBands_1D_512` | Zeros bins `< lowRatioÂ·N` and `> (1â€‘highRatio)Â·N` on both real & imag. Defaults:<br> `lowRatioÂ =Â 0`, `highRatioÂ =Â 0.9` (kills top 90â€¯% of spectrum). |
| **iFFT**           | `ifft1D_512`       | Same code base, reverse sign + `1/N` scale.                                                                                                          |
| **TransposeÂ back** | `transpose512`     | Returns data to rowâ€‘major so the CPU can convert to CGImage.                                                                                         |

**Buffers are allocated once** and reused; no perâ€‘frame `makeBuffer(bytes:)` calls.

```swift
/// Runtime knobs you can tweak from SwiftUI sliders
var lowRatio:  Float = 0.00   // kill low  freq bins (0â€¦1)
var highRatio: Float = 0.90   // kill high freq bins (0â€¦1)
```

---

## ðŸ§   Why *column* FFT?

The iPhone sensor delivers portraitâ€‘native pixels. Applying 1â€‘D FFT **across columns** produces glitches that follow the natural orientation (horizontal artefacts when the phone is held upright). Two cheap transpose passes (<0.05â€¯ms each) are faster than strided memory access in a columnâ€‘native FFT.

---

## ðŸ“ˆ  Performance (iPhoneÂ 15Â Pro)

* 512â€¯Ã—â€¯512 RGB â†’ GPU â†’ back â†’ display: **â‰ˆÂ 5.8â€¯ms**
* Sustains **60Â fps** with \~30â€¯% A17 GPU utilisation.
* CPU stays <3â€¯% because of persistent buffers.

---

## ðŸ—ºï¸  Directory map

```
Gleitzsch/
â”œâ”€â”€ Processing/
â”‚   â”œâ”€â”€ MetalFFTFilter.swift   # <â€” this file
â”‚   â”œâ”€â”€ FFTShader.metal        # kernels listed above
â”‚   â”œâ”€â”€ ImageFilters/â€¦         # optional CPU filters (chromatic, gamma, â€¦)
â”‚   â””â”€â”€ (legacy) FFTFilter.swift
â”œâ”€â”€ Pipeline/FramePipeline.swift  # frame throttling & offâ€‘mainâ€‘thread proc
â”œâ”€â”€ Camera/CameraManager.swift    # AVFoundation capture
â””â”€â”€ â€¦
```

---

## ðŸš§  Roadmap

* Expose `lowRatio` / `highRatio` / phaseâ€‘shift as UI sliders.
* Record processed video (AVAssetWriter).
* LivePhoto support / AppÂ Clip demo.
* Generic â€œmultiâ€‘filterâ€ graph once more GPU filters appear.

---

## ðŸ•°ï¸  Legacy / fallback CPU path

`FFTFilter.swift` (Accelerate/vDSP) still exists as a reference implementation and as a simulator fallback. It processes **rows** instead of columns and normalises each channel after iFFT.

Enable it by swapping the filter in **FrameProcessor**:

```swift
// graph.addFilter(MetalFFTFilter())
graph.addFilter(FFTFilter())
```

---

Happy glitching! âœ¨
